[net]
#Testing
batch=1

height=224
width=224
channels=3

[convolutional]
batch_normalize=1
filters=16
size=3
stride=2
pad=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=16
size=3
stride=1
pad=1
#groups=16
activation=relu6

[convolutional]
batch_normalize=1
filters=56
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=56
size=3
stride=2
pad=1
#groups=56
activation=relu6

[convolutional]
batch_normalize=1
filters=88
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=88
size=3
stride=1
pad=1
#groups=88
activation=relu6

[convolutional]
batch_normalize=1
filters=120
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=120
size=3
stride=2
pad=1
#groups=120
activation=relu6

[convolutional]
batch_normalize=1
filters=144
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=144
size=3
stride=1
pad=1
#groups=144
activation=relu6

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=256
size=3
stride=2
pad=1
#groups=256
activation=relu6

[convolutional]
batch_normalize=1
filters=408
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=408
size=3
stride=1
pad=1
#groups=408
activation=relu6

[convolutional]
batch_normalize=1
filters=376
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=376
size=3
stride=1
pad=1
#groups=376
activation=relu6

[convolutional]
batch_normalize=1
filters=272
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=272
size=3
stride=1
pad=1
#groups=272
activation=relu6

[convolutional]
batch_normalize=1
filters=288
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=288
size=3
stride=1
pad=1
#groups=288
activation=relu6

[convolutional]
batch_normalize=1
filters=296
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=296
size=3
stride=1
pad=1
#groups=296
activation=relu6

[convolutional]
batch_normalize=1
filters=328
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=328
size=3
stride=2
pad=1
#groups=328
activation=relu6

[convolutional]
batch_normalize=1
filters=480
size=1
stride=1
activation=relu6

[depthwise_convolutional]
batch_normalize=1
#filters=480
size=3
stride=1
pad=1
#groups=480
activation=relu6

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
activation=relu6

##decoder 1
[depthwise_convolutional]
batch_normalize=1
#filters=512
size=5
stride=1
pad=2
#groups=512
activation=leaky

[convolutional]
batch_normalize=1
filters=200
size=1
stride=1
activation=leaky

[upsample]
stride=2

##decoder 2
[depthwise_convolutional]
batch_normalize=1
#filters=200
size=5
stride=1
pad=2
#groups=200
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
activation=leaky

[upsample]
stride=2

[shortcut]
from=10
activation=leaky

##decoder 3
[depthwise_convolutional]
batch_normalize=1
#filters=256
size=5
stride=1
pad=2
#groups=256
activation=leaky

[convolutional]
batch_normalize=1
filters=120
size=1
stride=1
activation=leaky

[upsample]
stride=2

[shortcut]
from=6
activation=leaky

##decoder 4
[depthwise_convolutional]
batch_normalize=1
#filters=120
size=5
stride=1
pad=2
#groups=120
activation=leaky

[convolutional]
batch_normalize=1
filters=56
size=1
stride=1
activation=leaky

[upsample]
stride=2

[shortcut]
from=2
activation=leaky

##decoder 5
[depthwise_convolutional]
batch_normalize=1
#filters=56
size=5
stride=1
pad=2
#groups=56
activation=leaky

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
activation=leaky

[upsample]
stride=2

##decoder 6
[convolutional]
batch_normalize=1
filters=1
size=1
stride=1
activation=leaky
